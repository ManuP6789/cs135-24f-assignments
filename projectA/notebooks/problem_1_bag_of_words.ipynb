{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Bag-of-Words Feature Representation\n",
    "In this notebook, we will explore the concept of the Bag-of-Words (BoW) representation for text data and its two popular variations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of tr_list_of_sentences: 2400\n",
      "Length of y_train: 2400\n"
     ]
    }
   ],
   "source": [
    "x_train_df = pd.read_csv('../data_reviews/x_train.csv')\n",
    "y_train_df = pd.read_csv('../data_reviews/y_train.csv')\n",
    "\n",
    "# Convert the columns to lists/arrays\n",
    "x_train_unshuffled = x_train_df['text'].values.tolist()\n",
    "y = y_train_df['is_positive_sentiment'].values\n",
    "\n",
    "# Shuffle both X and y together\n",
    "X_train, y_train = shuffle(x_train_unshuffled, y, random_state=42)\n",
    "\n",
    "# Check the lengths\n",
    "print(f'Length of tr_list_of_sentences: {len(x_train_unshuffled)}')\n",
    "print(f'Length of y_train: {len(y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the training data, we will remove all the stop words and punctuations using the CountVectorizer method from the scikit-learn library. We will also use the same CountVectorizer method to transform the test data. We will also be using the unigram method to help us understand the concept of BoW representation better and excclude words that appear in less than 5 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4510\n"
     ]
    }
   ],
   "source": [
    "# Creating the pipeline\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "# Fit the vectorizer to the data\n",
    "X = vectorizer.fit_transform(X_train)  # 'documents' is your input text data\n",
    "\n",
    "# Print the size of the vocabulary\n",
    "print(\"Vocabulary size:\", len(vectorizer.vocabulary_))\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('tfidf', TfidfTransformer(smooth_idf=True, use_idf=True, sublinear_tf=True)),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hyperparameter tuning, we will use the GridSearchCV method from the scikit-learn library to find the best hyperparameters for the Logistic Regression model. We will also use the accuracy score to evaluate the model's performance. We also use two different logistic regressions models(one based on quasi-newton method and other based on stochastic gradient descent) to compare the performance of the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "375 fits failed out of a total of 750.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "125 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/manuelpena/micromamba/envs/cs135_env/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan 0.5\n",
      " 0.5        0.5        0.5        0.5        0.75732813 0.83239063\n",
      " 0.84585764 0.85364931 0.85364931 0.7573559  0.83232118 0.84588889\n",
      " 0.85366319 0.85364931        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.71494618\n",
      " 0.67460417 0.65479167 0.65010937 0.65010937 0.7646059  0.84634896\n",
      " 0.85894444 0.86518403 0.86518403 0.76456771 0.84638715 0.85895833\n",
      " 0.8651875  0.86518056        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.76973785\n",
      " 0.87012847 0.86997743 0.86187153 0.86199306 0.76557465 0.86592535\n",
      " 0.88329514 0.89276042 0.89276042 0.76572049 0.86586979 0.88333681\n",
      " 0.89280903 0.89277431        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.76396528\n",
      " 0.85383507 0.86507986 0.89007465 0.89004688 0.76382118 0.85960243\n",
      " 0.87901042 0.90169097 0.90169097 0.76378299 0.85959896 0.87903819\n",
      " 0.90166667 0.90171875        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.76304687\n",
      " 0.8268941  0.81997049 0.88770486 0.88778125 0.76289757 0.84205729\n",
      " 0.84602778 0.89294792 0.89294792 0.76293229 0.8420816  0.84614236\n",
      " 0.89287847 0.893             nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;,\n",
       "                                        TfidfTransformer(sublinear_tf=True)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                           max_iter=1000))]),\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;classifier__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;classifier__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;],\n",
       "                         &#x27;vectorizer__max_features&#x27;: [100, 500, 1000, 10000,\n",
       "                                                      100000]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                                       (&#x27;tfidf&#x27;,\n",
       "                                        TfidfTransformer(sublinear_tf=True)),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                           max_iter=1000))]),\n",
       "             param_grid={&#x27;classifier__C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;classifier__penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;classifier__solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;saga&#x27;],\n",
       "                         &#x27;vectorizer__max_features&#x27;: [100, 500, 1000, 10000,\n",
       "                                                      100000]},\n",
       "             scoring=&#x27;roc_auc&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-70\" type=\"checkbox\" ><label for=\"sk-estimator-id-70\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;tfidf&#x27;, TfidfTransformer(sublinear_tf=True)),\n",
       "                (&#x27;classifier&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-71\" type=\"checkbox\" ><label for=\"sk-estimator-id-71\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-72\" type=\"checkbox\" ><label for=\"sk-estimator-id-72\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer(sublinear_tf=True)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-73\" type=\"checkbox\" ><label for=\"sk-estimator-id-73\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=1000)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                                       ('tfidf',\n",
       "                                        TfidfTransformer(sublinear_tf=True)),\n",
       "                                       ('classifier',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           max_iter=1000))]),\n",
       "             param_grid={'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'classifier__penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'classifier__solver': ['lbfgs', 'saga'],\n",
       "                         'vectorizer__max_features': [100, 500, 1000, 10000,\n",
       "                                                      100000]},\n",
       "             scoring='roc_auc')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'classifier__solver': ['lbfgs', 'saga'],\n",
    "    'vectorizer__max_features': [100, 500, 1000, 10000, 100000],\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2', 'elasticnet']\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'classifier__C': 10, 'classifier__penalty': 'l2', 'classifier__solver': 'saga', 'vectorizer__max_features': 100000}\n",
      "Best cross-validation AUC:  0.90171875\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation AUC: \", grid_search.best_score_)\n",
    "\n",
    "# # Use the best estimator from GridSearchCV to make predictions\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "# LEADERBOARD: 0.91283  postion 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1200\n",
      "           1       1.00      0.99      0.99      1200\n",
      "\n",
      "    accuracy                           0.99      2400\n",
      "   macro avg       0.99      0.99      0.99      2400\n",
      "weighted avg       0.99      0.99      0.99      2400\n",
      "\n",
      "[[1196    4]\n",
      " [  15 1185]]\n",
      "AUC: 0.9987\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.best_estimator_.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred))\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "\n",
    "y_pred_prob = grid_search.best_estimator_.predict_proba(X_train)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_train, y_pred_prob)\n",
    "\n",
    "print(f'AUC: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilistic predictions saved to '../data_reviews/yproba1_test.txt'.\n"
     ]
    }
   ],
   "source": [
    "# Load the test data\n",
    "x_test_df = pd.read_csv('../data_reviews/x_test.csv')\n",
    "\n",
    "# Get the predicted probabilities for the positive class\n",
    "y_test_pred_prob = grid_search.best_estimator_.predict_proba(x_test_df['text'])[:, 1]\n",
    "\n",
    "# Save the probabilities to a plain-text file\n",
    "with open('../data_reviews/yproba1_test.txt', 'w') as f:\n",
    "    for prob in y_test_pred_prob:\n",
    "        f.write(f\"{prob:.6f}\\n\")  # Formatting to six decimal places\n",
    "\n",
    "print(\"Probabilistic predictions saved to '../data_reviews/yproba1_test.txt'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
